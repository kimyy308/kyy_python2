{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e489583-5013-4f4c-8db6-bbb1d71cb742",
   "metadata": {},
   "source": [
    "# Module and DASK setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd30181f-20f3-4a95-ab67-43b59276f4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/all/Model/CESM2/Earth_System_Predictability/ASSM/Aleph'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DASK client set\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dask.distributed import Client\n",
    "# client = Client(scheduler_file='/proj/kimyy/Dropbox/source/python/all/mpi/scheduler.json', threads_per_worker=2, n_workers=6)\n",
    "client = Client(scheduler_file='/proj/kimyy/Dropbox/source/python/all/mpi/scheduler.json')\n",
    "# client = Client(scheduler_file='/proj/kimyy/Dropbox/source/python/all/mpi/scheduler_10.json')  \n",
    "\n",
    "def setup_module_path():\n",
    "    module_path = '/proj/kimyy/Dropbox/source/python/all/Modules/CESM2'\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "client.run(setup_module_path)\n",
    "\n",
    "client\n",
    "\n",
    "# get path for path changes in Jupyter notebook: File - Open from Path - insert relative_path\n",
    "notebook_path = os.path.abspath(\".\")\n",
    "_, _, relative_path = notebook_path.partition('/all/')\n",
    "relative_path = '/all/' + relative_path\n",
    "relative_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d374e9-1530-41fc-ac08-850302ae14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load public modules\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.path as mpath\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy import stats\n",
    "from scipy.interpolate import griddata\n",
    "import cmocean\n",
    "from cmcrameri import cm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import pop_tools\n",
    "from pprint import pprint\n",
    "import time\n",
    "import subprocess\n",
    "import re as re_mod\n",
    "import cftime\n",
    "import datetime\n",
    "from scipy.stats import ttest_1samp\n",
    "import xcesm\n",
    "# from scipy.stats import pearsonr\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23400be5-6517-4bb2-9be9-fa0b74cd4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load private modules\n",
    "\n",
    "import sys\n",
    "sys.path.append('/proj/kimyy/Dropbox/source/python/all/Modules/CESM2')\n",
    "from KYY_CESM2_preprocessing import CESM2_config\n",
    "\n",
    "savefilepath = \"/mnt/lustre/proj/kimyy/tmp_python/HCST_skills_autocorr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a146a7-52ee-414e-8cb7-c35a0ffb66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change variables by command+F, for S-ST, T-REFHT, T-WS, P-SL, P-RECT, G-PP, S-SH, p-hotoC_TOT_zint_100m, F-AREA_BURNED (not for N-O3). \n",
    "\n",
    "cfg_var_NO3=CESM2_config()\n",
    "cfg_var_NO3.year_s=1960\n",
    "cfg_var_NO3.year_e=2020\n",
    "cfg_var_NO3.setvar('NO3')\n",
    "cfg_var_NO3.OBS_var = 'nan'\n",
    "start_date = cftime.DatetimeNoLeap(cfg_var_NO3.year_s, 2, 1)\n",
    "end_date = cftime.DatetimeNoLeap(cfg_var_NO3.year_e+1, 1, 1)\n",
    "\n",
    "ds_grid = pop_tools.get_grid('POP_gx1v7')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a54a9bb-24d5-4126-a550-0666be056dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_var_NO3.OBS_var = 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96be5df-9c61-456f-aa74-00d3928c9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_coords_2d(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        ds = ds.sel(time=slice(sd, ed))\n",
    "\n",
    "        new_time = ds.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds = ds.assign_coords(time=new_time)      \n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)\n",
    "\n",
    "def process_coords_surface(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        ds = ds.sel(time=slice(sd, ed))\n",
    "        ds = ds.isel(z_t=0) \n",
    "        # ds_rgd = ds[varname].utils.regrid()\n",
    "\n",
    "        new_time = ds.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds = ds.assign_coords(time=new_time)\n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)\n",
    "\n",
    "\n",
    "\n",
    "def process_coords_2d_obs(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "\n",
    "    if drop:\n",
    "\n",
    "        if 'T' in ds.coords or 'T' in ds.dims:\n",
    "            ds = ds.rename({'T': 'time'})\n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)\n",
    "\n",
    "\n",
    "def process_coords_2d_hcst(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        # ds_rgd = ds[varname].utils.regrid()\n",
    "        # new_time = ds_rgd.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        # ds_rgd = ds_rgd.assign_coords(time=new_time)\n",
    "        new_time = ds.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds = ds.assign_coords(time=new_time)\n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)\n",
    "\n",
    "\n",
    "def process_coords_surface_hcst(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        # ds = ds.isel(z_t_150m=slice(0,10)) \n",
    "        ds = ds.isel(z_t=0) \n",
    "        # ds_rgd = ds[varname].utils.regrid()\n",
    "\n",
    "        new_time = ds.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds = ds.assign_coords(time=new_time)\n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d6f6bc-14d4-490c-a135-27db02976d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for reading ODA, 0: 74.62341022491455\n",
      "elasped time for reading ODA, 1: 148.36190915107727\n",
      "elasped time for reading ODA, 2: 219.9632408618927\n",
      "elasped time for reading ODA, 3: 294.2169530391693\n",
      "elasped time for reading ODA, 4: 363.48272013664246\n",
      "elasped time for reading ODA, 5: 440.5602767467499\n",
      "elasped time for reading ODA, 6: 509.79437923431396\n",
      "elasped time for reading ODA, 7: 578.7457957267761\n",
      "elasped time for reading ODA, 8: 648.8710770606995\n",
      "elasped time for reading ODA, 9: 720.3828880786896\n",
      "elasped time for reading ODA, 10: 785.4098088741302\n",
      "elasped time for reading ODA, 11: 852.6737434864044\n",
      "elasped time for reading ODA, 12: 919.8347978591919\n",
      "elasped time for reading ODA, 13: 982.7610414028168\n",
      "elasped time for reading ODA, 14: 1047.1239540576935\n",
      "elasped time for reading ODA, 15: 1118.424021244049\n",
      "elasped time for reading ODA, 16: 1183.6339428424835\n",
      "elasped time for reading ODA, 17: 1249.9023110866547\n",
      "elasped time for reading ODA, 18: 1315.4203963279724\n",
      "elasped time for reading ODA, 19: 1391.0757818222046\n",
      "elasped time for reading ODA, 19: 1763.2290465831757\n"
     ]
    }
   ],
   "source": [
    "# Read ODA dataset (NO3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cfg_var_NO3.ODA_path_load(cfg_var_NO3.var)\n",
    "\n",
    "tmp_comp=cfg_var_NO3.comp\n",
    "cfg_var_NO3.ODA_ds = []\n",
    "for imem in range(0, len(cfg_var_NO3.ODA_file_list[0])):\n",
    "    NO3_ODA_ds_tmp = xr.open_mfdataset(cfg_var_NO3.ODA_file_list[0][imem], \n",
    "                           chunks={'time': 5}, \n",
    "                           combine='nested',\n",
    "                           parallel=True,\n",
    "                           preprocess=lambda ds: process_coords_surface(ds, start_date, end_date, 'NO3', tmp_comp),\n",
    "                           decode_cf=True, \n",
    "                           decode_times=True)\n",
    "    \n",
    "    NO3_ODA_ds_tmp = NO3_ODA_ds_tmp.expand_dims({'ens_ODA': 1})\n",
    "    cfg_var_NO3.ODA_ds.append(NO3_ODA_ds_tmp)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('elasped time for reading ODA, ' + str(imem) + ': ' + str(elapsed_time))\n",
    "\n",
    "cfg_var_NO3.ODA_ds = xr.concat(cfg_var_NO3.ODA_ds, dim='ens_ODA')\n",
    "cfg_var_NO3.ODA_ds['ens_ODA']=range(0, len(cfg_var_NO3.ODA_file_list[0]))\n",
    "cfg_var_NO3.ODA_ds=cfg_var_NO3.ODA_ds.compute()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for reading ODA, ' + str(imem) + ': ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f25d1caa-4568-45bd-87d7-66c8c811cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for reading LE, 0: 54.70848989486694\n",
      "elasped time for reading LE, 1: 96.36748456954956\n",
      "elasped time for reading LE, 2: 140.1586754322052\n",
      "elasped time for reading LE, 3: 183.7445194721222\n",
      "elasped time for reading LE, 4: 228.88884925842285\n",
      "elasped time for reading LE, 5: 274.0359888076782\n",
      "elasped time for reading LE, 6: 320.6613619327545\n",
      "elasped time for reading LE, 7: 363.5642306804657\n",
      "elasped time for reading LE, 8: 406.83827233314514\n",
      "elasped time for reading LE, 9: 450.9124381542206\n",
      "elasped time for reading LE, 10: 488.1293435096741\n",
      "elasped time for reading LE, 11: 525.7322189807892\n",
      "elasped time for reading LE, 12: 560.7542510032654\n",
      "elasped time for reading LE, 13: 596.3222925662994\n",
      "elasped time for reading LE, 14: 632.4994781017303\n",
      "elasped time for reading LE, 15: 668.1446907520294\n",
      "elasped time for reading LE, 16: 703.5543518066406\n",
      "elasped time for reading LE, 17: 743.3858289718628\n",
      "elasped time for reading LE, 18: 787.665876865387\n",
      "elasped time for reading LE, 19: 824.9905061721802\n",
      "elasped time for reading LE, 20: 861.5505602359772\n",
      "elasped time for reading LE, 21: 899.3538269996643\n",
      "elasped time for reading LE, 22: 937.1823234558105\n",
      "elasped time for reading LE, 23: 972.4010453224182\n",
      "elasped time for reading LE, 24: 1012.907952785492\n",
      "elasped time for reading LE, 25: 1054.1871757507324\n",
      "elasped time for reading LE, 26: 1090.5251519680023\n",
      "elasped time for reading LE, 27: 1134.1283557415009\n",
      "elasped time for reading LE, 28: 1174.0136318206787\n",
      "elasped time for reading LE, 29: 1213.4828126430511\n",
      "elasped time for reading LE, 30: 1253.6005599498749\n",
      "elasped time for reading LE, 31: 1291.203754901886\n",
      "elasped time for reading LE, 32: 1333.4072897434235\n",
      "elasped time for reading LE, 33: 1369.4298856258392\n",
      "elasped time for reading LE, 34: 1405.685821056366\n",
      "elasped time for reading LE, 35: 1442.04434466362\n",
      "elasped time for reading LE, 36: 1480.764553785324\n",
      "elasped time for reading LE, 37: 1520.0090327262878\n",
      "elasped time for reading LE, 38: 1556.8179244995117\n",
      "elasped time for reading LE, 39: 1594.198963880539\n",
      "elasped time for reading LE, 40: 1630.5336000919342\n",
      "elasped time for reading LE, 41: 1669.4965097904205\n",
      "elasped time for reading LE, 42: 1707.7259838581085\n",
      "elasped time for reading LE, 43: 1746.2750091552734\n",
      "elasped time for reading LE, 44: 1785.99205493927\n",
      "elasped time for reading LE, 45: 1831.44322681427\n",
      "elasped time for reading LE, 46: 1881.3579018115997\n",
      "elasped time for reading LE, 47: 1925.1618249416351\n",
      "elasped time for reading LE, 48: 1968.703491449356\n",
      "elasped time for reading LE, 49: 2013.1586112976074\n",
      "elasped time for reading LE, 49: 3522.055671453476\n"
     ]
    }
   ],
   "source": [
    "# Read LE dataset (NO3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cfg_var_NO3.LE_path_load(cfg_var_NO3.var)\n",
    "\n",
    "fpath_NO3 = savefilepath + \"/LE_NO3_output*.nc\"\n",
    "\n",
    "tmp_comp=cfg_var_NO3.comp\n",
    "cfg_var_NO3.LE_ds = []\n",
    "for imem in range(0, len(cfg_var_NO3.LE_file_list[0])):\n",
    "    NO3_LE_ds_tmp = xr.open_mfdataset(cfg_var_NO3.LE_file_list[0][imem], \n",
    "                           chunks={'time': 5}, \n",
    "                           combine='nested',\n",
    "                           parallel=True,\n",
    "                           preprocess=lambda ds: process_coords_surface(ds, start_date, end_date, 'NO3', tmp_comp),\n",
    "                           decode_cf=True, \n",
    "                           decode_times=True)\n",
    "    \n",
    "    NO3_LE_ds_tmp = NO3_LE_ds_tmp.expand_dims({'ens_LE': 1})\n",
    "    cfg_var_NO3.LE_ds.append(NO3_LE_ds_tmp)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('elasped time for reading LE, ' + str(imem) + ': ' + str(elapsed_time))\n",
    "\n",
    "cfg_var_NO3.LE_ds = xr.concat(cfg_var_NO3.LE_ds, dim='ens_LE')\n",
    "cfg_var_NO3.LE_ds['ens_LE']=range(0, len(cfg_var_NO3.LE_file_list[0]))\n",
    "cfg_var_NO3.LE_ds=cfg_var_NO3.LE_ds.compute()\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for reading LE, ' + str(imem) + ': ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e81b47d4-73da-4b5d-b4ab-664b308438fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for reading HCST NO3, 0: 28.442138671875\n",
      "elasped time for reading HCST NO3, 1: 33.0088152885437\n",
      "elasped time for reading HCST NO3, 2: 37.62539768218994\n",
      "elasped time for reading HCST NO3, 3: 42.31944513320923\n",
      "elasped time for reading HCST NO3, 4: 46.81011724472046\n",
      "elasped time for reading HCST NO3, 5: 51.33808398246765\n",
      "elasped time for reading HCST NO3, 6: 55.989657402038574\n",
      "elasped time for reading HCST NO3, 7: 60.6488778591156\n",
      "elasped time for reading HCST NO3, 8: 65.86664843559265\n",
      "elasped time for reading HCST NO3, 9: 70.37450361251831\n",
      "elasped time for reading HCST NO3, 10: 74.95180678367615\n",
      "elasped time for reading HCST NO3, 11: 79.52054691314697\n",
      "elasped time for reading HCST NO3, 12: 84.10340881347656\n",
      "elasped time for reading HCST NO3, 13: 88.74954223632812\n",
      "elasped time for reading HCST NO3, 14: 93.27501630783081\n",
      "elasped time for reading HCST NO3, 15: 97.98826432228088\n",
      "elasped time for reading HCST NO3, 16: 103.54740571975708\n",
      "elasped time for reading HCST NO3, 17: 108.19986152648926\n",
      "elasped time for reading HCST NO3, 18: 112.76480531692505\n",
      "elasped time for reading HCST NO3, 19: 117.2658019065857\n",
      "elasped time for reading HCST NO3, 20: 121.90434718132019\n",
      "elasped time for reading HCST NO3, 21: 126.54052972793579\n",
      "elasped time for reading HCST NO3, 22: 131.08695459365845\n",
      "elasped time for reading HCST NO3, 23: 135.63082456588745\n",
      "elasped time for reading HCST NO3, 24: 140.51884627342224\n",
      "elasped time for reading HCST NO3, 25: 144.9490020275116\n",
      "elasped time for reading HCST NO3, 26: 150.1961669921875\n",
      "elasped time for reading HCST NO3, 27: 154.79070663452148\n",
      "elasped time for reading HCST NO3, 28: 159.46611261367798\n",
      "elasped time for reading HCST NO3, 29: 164.10678219795227\n",
      "elasped time for reading HCST NO3, 30: 168.65839290618896\n",
      "elasped time for reading HCST NO3, 31: 173.74042081832886\n",
      "elasped time for reading HCST NO3, 32: 178.3205966949463\n",
      "elasped time for reading HCST NO3, 33: 182.8676736354828\n",
      "elasped time for reading HCST NO3, 34: 187.8618562221527\n",
      "elasped time for reading HCST NO3, 35: 192.38658356666565\n",
      "elasped time for reading HCST NO3, 36: 197.07614517211914\n",
      "elasped time for reading HCST NO3, 37: 202.34914088249207\n",
      "elasped time for reading HCST NO3, 38: 206.93644499778748\n",
      "elasped time for reading HCST NO3, 39: 211.5193109512329\n",
      "elasped time for reading HCST NO3, 40: 216.0018527507782\n",
      "elasped time for reading HCST NO3, 41: 220.50773072242737\n",
      "elasped time for reading HCST NO3, 42: 225.01188778877258\n",
      "elasped time for reading HCST NO3, 43: 229.65845680236816\n",
      "elasped time for reading HCST NO3, 44: 234.29497957229614\n",
      "elasped time for reading HCST NO3, 45: 239.12865495681763\n",
      "elasped time for reading HCST NO3, 46: 244.16482710838318\n",
      "elasped time for reading HCST NO3, 47: 249.29457330703735\n",
      "elasped time for reading HCST NO3, 48: 254.17554330825806\n",
      "elasped time for reading HCST NO3, 49: 259.42354440689087\n",
      "elasped time for reading HCST NO3, 50: 264.43879294395447\n",
      "elasped time for reading HCST NO3, 51: 269.88640570640564\n",
      "elasped time for reading HCST NO3, 52: 275.30807662010193\n",
      "elasped time for reading HCST NO3, 53: 280.7862319946289\n",
      "elasped time for reading HCST NO3, 54: 286.6093535423279\n",
      "elasped time for reading HCST NO3, 55: 291.27344155311584\n",
      "elasped time for reading HCST NO3, 56: 295.9280776977539\n",
      "elasped time for reading HCST NO3, 57: 300.433837890625\n",
      "elasped time for reading HCST NO3, 58: 305.71157026290894\n",
      "elasped time for reading HCST NO3, 59: 310.3452687263489\n",
      "elasped time for reading HCST NO3, 60: 316.208664894104\n",
      "elasped time for reading HCST NO3, 60: 3316.2168910503387\n"
     ]
    }
   ],
   "source": [
    "# HCST NO3\n",
    "\n",
    "cfg_var_NO3.HCST_ds = []\n",
    "HCST_ds_xr = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cfg_var_NO3.HCST_path_load(cfg_var_NO3.var)\n",
    "\n",
    "for iyear in range(0, len(cfg_var_NO3.HCST_file_list)):\n",
    "    NO3_HCST_ds_tmp = xr.open_mfdataset(cfg_var_NO3.HCST_file_list[iyear], \n",
    "                           chunks={'time': 4}, \n",
    "                           combine='nested',\n",
    "                           concat_dim=[[*cfg_var_NO3.HCST_ensembles], 'year'], \n",
    "                           parallel=True,\n",
    "                           preprocess=lambda ds: process_coords_surface_hcst(ds, start_date, end_date, 'NO3', tmp_comp),\n",
    "                           decode_cf=True, \n",
    "                           decode_times=True)\n",
    "    \n",
    "    NO3_HCST_ds_tmp = NO3_HCST_ds_tmp.rename({\"year\": \"lyears\"})\n",
    "    NO3_HCST_ds_tmp['lyears']=range(1,6)\n",
    "    NO3_HCST_ds_tmp = NO3_HCST_ds_tmp.expand_dims({'iyear': 1})\n",
    "    \n",
    "    cfg_var_NO3.HCST_ds.append(NO3_HCST_ds_tmp)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('elasped time for reading HCST NO3, ' + str(iyear) + ': ' + str(elapsed_time))\n",
    "\n",
    "cfg_var_NO3.HCST_ds = xr.concat(cfg_var_NO3.HCST_ds, dim='iyear')\n",
    "cfg_var_NO3.HCST_ds = cfg_var_NO3.HCST_ds.rename({\"concat_dim\": \"ens_HCST\"})\n",
    "cfg_var_NO3.HCST_ds['ens_HCST']=range(0, len(cfg_var_NO3.HCST_file_list[0]))\n",
    "cfg_var_NO3.HCST_ds['iyear']=range(cfg_var_NO3.year_s, cfg_var_NO3.year_e+1)\n",
    "cfg_var_NO3.HCST_ds=cfg_var_NO3.HCST_ds.compute()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for reading HCST NO3, ' + str(iyear) + ': ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b3bb7f-bd1f-4f8e-aa77-3de530cb5ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_var_NO3.HCST_ds_yearly = cfg_var_NO3.HCST_ds.sel(iyear=slice(\"1960-01-01\", \"2020-12-31\")).isel(lyears=0).rename({\"iyear\": \"year\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a4cc741-848e-4dfa-9320-839b4dd82878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rolling mean variables (NO3)\n",
    "\n",
    "cfg_var_NO3.ODA_ds_4yr = cfg_var_NO3.ODA_ds.rolling(year=4, min_periods=4).mean()\n",
    "obs_rolling_time_mean = cfg_var_NO3.ODA_ds['year'].rolling(year=4, min_periods=4).mean()\n",
    "cfg_var_NO3.ODA_ds_4yr = cfg_var_NO3.ODA_ds_4yr.assign_coords(year=obs_rolling_time_mean)\n",
    "valid_index = np.where(~np.isnan(cfg_var_NO3.ODA_ds_4yr['year']))[0]\n",
    "cfg_var_NO3.ODA_ds_4yr = cfg_var_NO3.ODA_ds_4yr.isel(year=valid_index)\n",
    "cfg_var_NO3.ODA_ds_4yr = cfg_var_NO3.ODA_ds_4yr.isel(year=range(1,58))\n",
    "\n",
    "cfg_var_NO3.LE_ds_4yr = cfg_var_NO3.LE_ds.rolling(year=4, min_periods=4).mean()\n",
    "obs_rolling_time_mean = cfg_var_NO3.LE_ds['year'].rolling(year=4, min_periods=4).mean()\n",
    "cfg_var_NO3.LE_ds_4yr = cfg_var_NO3.LE_ds_4yr.assign_coords(year=obs_rolling_time_mean)\n",
    "valid_index = np.where(~np.isnan(cfg_var_NO3.LE_ds_4yr['year']))[0]\n",
    "cfg_var_NO3.LE_ds_4yr = cfg_var_NO3.LE_ds_4yr.isel(year=valid_index)\n",
    "cfg_var_NO3.LE_ds_4yr = cfg_var_NO3.LE_ds_4yr.isel(year=range(1,58))\n",
    "\n",
    "# hcst_da_ly25=cfg_var_NO3.HCST_ds.sel(iyear=slice(\"1996-01-01\", \"2016-12-31\"), lyears=slice(2, 5))\n",
    "hcst_da_ly25=cfg_var_NO3.HCST_ds.sel(iyear=slice(\"1959\", \"2016\"), lyears=slice(2, 5))\n",
    "cfg_var_NO3.HCST_ds_4yr=hcst_da_ly25.mean(dim='lyears')\n",
    "cfg_var_NO3.HCST_ds_4yr=cfg_var_NO3.HCST_ds_4yr.rename(iyear=\"year\")\n",
    "cfg_var_NO3.HCST_ds_4yr['year']=cfg_var_NO3.LE_ds_4yr['year']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9506a367-76e1-4c03-b8d8-d17ca2c54dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# individual (ODA)\n",
    "da = cfg_var_NO3.ODA_ds['NO3'].sel(year=slice(1965, 2020))\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "autocorr_NO3_ODA = xr.corr(da, da_lag1, dim='year')   # ens_ODA, lat, lon\n",
    "\n",
    "\n",
    "# ensemble mean (ODA)\n",
    "da = cfg_var_NO3.ODA_ds['NO3'].sel(year=slice(1965, 2020)).mean(dim='ens_ODA')\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "autocorr_NO3_ODA_em = xr.corr(da, da_lag1, dim='year')   # ens_ODA, lat, lon\n",
    "\n",
    "\n",
    "# individual 4yr (ODA)\n",
    "da = cfg_var_NO3.ODA_ds_4yr['NO3'].sel(year=slice(1965, 2020))\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "\n",
    "autocorr_NO3_ODA_ds_4yr = xr.corr(da, da_lag1, dim='year')   # ens_ODA, lat, lon\n",
    "\n",
    "\n",
    "# ensemble mena 4yr (ODA)\n",
    "da = cfg_var_NO3.ODA_ds_4yr['NO3'].sel(year=slice(1965, 2020)).mean(dim='ens_ODA')\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "\n",
    "autocorr_NO3_ODA_ds_4yr_em = xr.corr(da, da_lag1, dim='year')   # ens_ODA, lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d634508e-bfbd-4d13-9eb5-b6126d5a944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# individual (LE)\n",
    "da = cfg_var_NO3.LE_ds['NO3'].sel(year=slice(1965, 2020))\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "autocorr_NO3_LE = xr.corr(da, da_lag1, dim='year')   # ens_LE, lat, lon\n",
    "\n",
    "\n",
    "# ensemble mean (LE)\n",
    "da = cfg_var_NO3.LE_ds['NO3'].sel(year=slice(1965, 2020)).mean(dim='ens_LE')\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "autocorr_NO3_LE_em = xr.corr(da, da_lag1, dim='year')   # ens_LE, lat, lon\n",
    "\n",
    "\n",
    "# individual 4yr (LE)\n",
    "da = cfg_var_NO3.LE_ds_4yr['NO3'].sel(year=slice(1965, 2020))\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "\n",
    "autocorr_NO3_LE_ds_4yr = xr.corr(da, da_lag1, dim='year')   # ens_LE, lat, lon\n",
    "\n",
    "\n",
    "# ensemble mena 4yr (LE)\n",
    "da = cfg_var_NO3.LE_ds_4yr['NO3'].sel(year=slice(1965, 2020)).mean(dim='ens_LE')\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "\n",
    "autocorr_NO3_LE_ds_4yr_em = xr.corr(da, da_lag1, dim='year')   # ens_LE, lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65902950-871b-4800-b73c-1c6b9c086b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# individual (HCST)\n",
    "da = cfg_var_NO3.HCST_ds_yearly['NO3'].sel(year=slice(1965, 2020))\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "\n",
    "autocorr_NO3_HCST = xr.corr(da, da_lag1, dim='year')   # ens_LE, lat, lon\n",
    "\n",
    "\n",
    "# ensemble mean (HCST)\n",
    "da = cfg_var_NO3.HCST_ds_yearly['NO3'].sel(year=slice(1965, 2020)).mean(dim='ens_HCST')\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "\n",
    "autocorr_NO3_HCST_em = xr.corr(da, da_lag1, dim='year')   # ens_LE, lat, lon\n",
    "\n",
    "\n",
    "# individual 4yr (HCST)\n",
    "da = cfg_var_NO3.HCST_ds_4yr['NO3'].sel(year=slice(1965, 2020))\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "\n",
    "autocorr_NO3_HCST_ds_4yr = xr.corr(da, da_lag1, dim='year')   # ens_LE, lat, lon\n",
    "\n",
    "\n",
    "#ensemble mean 4yr (HCST)\n",
    "da = cfg_var_NO3.HCST_ds_4yr['NO3'].sel(year=slice(1965, 2020)).mean(dim='ens_HCST')\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_NO3.OBS_var == 'NO3' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "\n",
    "autocorr_NO3_HCST_ds_4yr_em = xr.corr(da, da_lag1, dim='year')   # ens_LE, lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92422643-b234-43d4-b117-4f772fbc9c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for saving NO3 corr, 60: 1.3934228420257568\n"
     ]
    }
   ],
   "source": [
    "# save temporary file (HCST)\n",
    "start_time = time.time()\n",
    "\n",
    "autocorr_NO3_ODA.to_netcdf(savefilepath + \"/autocorr_NO3_ODA\" + \".nc\")\n",
    "autocorr_NO3_ODA_em.to_netcdf(savefilepath + \"/autocorr_NO3_ODA_em\" + \".nc\")\n",
    "autocorr_NO3_ODA_ds_4yr.to_netcdf(savefilepath + \"/autocorr_NO3_ODA_ds_4yr\" + \".nc\")\n",
    "autocorr_NO3_ODA_ds_4yr_em.to_netcdf(savefilepath + \"/autocorr_NO3_ODA_ds_4yr_em\" + \".nc\")\n",
    "\n",
    "\n",
    "autocorr_NO3_LE.to_netcdf(savefilepath + \"/autocorr_NO3_LE\" + \".nc\")\n",
    "autocorr_NO3_LE_em.to_netcdf(savefilepath + \"/autocorr_NO3_LE_em\" + \".nc\")\n",
    "autocorr_NO3_LE_ds_4yr.to_netcdf(savefilepath + \"/autocorr_NO3_LE_ds_4yr\" + \".nc\")\n",
    "autocorr_NO3_LE_ds_4yr_em.to_netcdf(savefilepath + \"/autocorr_NO3_LE_ds_4yr_em\" + \".nc\")\n",
    "\n",
    "\n",
    "autocorr_NO3_HCST.to_netcdf(savefilepath + \"/autocorr_NO3_HCST\" + \".nc\")\n",
    "autocorr_NO3_HCST_em.to_netcdf(savefilepath + \"/autocorr_NO3_HCST_em\" + \".nc\")\n",
    "autocorr_NO3_HCST_ds_4yr.to_netcdf(savefilepath + \"/autocorr_NO3_HCST_ds_4yr\" + \".nc\")\n",
    "autocorr_NO3_HCST_ds_4yr_em.to_netcdf(savefilepath + \"/autocorr_NO3_HCST_ds_4yr_em\" + \".nc\")\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for saving NO3 corr, ' + str(iyear) + ': ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28f67c3e-b6ce-44da-b21c-048409cc8c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/lustre/proj/kimyy/tmp_python/HCST_skills_autocorr'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savefilepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d340dc5-8426-4870-bc25-39ac0f1931fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=10.37, alpha=0.1, df=8.37\n",
      "t_crit = 1.849\n",
      "Correlation threshold ≈ ±0.539\n"
     ]
    }
   ],
   "source": [
    "# critical r with alpha=0.1, alpha=0.34\n",
    "N = 10.37\n",
    "alpha = 0.1  # two-sided, so alpha/2 = 0.05\n",
    "df = N - 2\n",
    "\n",
    "# 1) Find t_crit for a two-sided test at alpha=0.1\n",
    "t_crit = t.ppf(1 - alpha/2, df)  # e.g., ppf(0.95) for the upper 5% tail\n",
    "\n",
    "# 2) Solve for the correlation threshold\n",
    "rho_crit = np.sqrt(t_crit**2 / ((N - 2) + t_crit**2))\n",
    "print(f\"N={N}, alpha={alpha}, df={df}\")\n",
    "print(f\"t_crit = {t_crit:.3f}\")\n",
    "print(f\"Correlation threshold ≈ ±{rho_crit:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7624f88d-8690-438c-b59b-0f672988567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_var_NO3.OBS_ds['lat']=cfg_var_NO3.HCST_ds_yearly['lat']\n",
    "# cfg_var_NO3.OBS_ds['lon']=cfg_var_NO3.HCST_ds_yearly['lon']\n",
    "# hcst_skill = xr.corr(cfg_var_NO3.OBS_ds['NO3'].sel(year=slice(1965, 2020)),\n",
    "#                      cfg_var_NO3.HCST_ds_yearly['NO3'].sel(year=slice(1965, 2020)),\n",
    "#                      dim='year')\n",
    "\n",
    "# le_skill = xr.corr(cfg_var_NO3.OBS_ds['NO3'].sel(year=slice(1965, 2020)),\n",
    "#                      cfg_var_NO3.LE_ds['NO3'].sel(year=slice(1965, 2020)),\n",
    "#                      dim='year')\n",
    "\n",
    "\n",
    "# common_years = np.intersect1d(cfg_var_NO3.OBS_ds.year, \n",
    "#                               cfg_var_NO3.HCST_ds_yearly.year)\n",
    "\n",
    "hcst_le_skill = xr.corr(cfg_var_NO3.HCST_ds_yearly['NO3'].sel(year=slice(1965, 2020)),\n",
    "                     cfg_var_NO3.LE_ds['NO3'].sel(year=slice(1965, 2020)),\n",
    "                     dim='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f62692f2-8117-491f-ab14-9a4ed94542ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcst_le_skill.to_netcdf(savefilepath + \"/hcst_le_skill_obs_NO3\" + \".nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
