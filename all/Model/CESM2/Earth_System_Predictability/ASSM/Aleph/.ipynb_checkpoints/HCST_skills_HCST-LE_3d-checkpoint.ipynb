{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e489583-5013-4f4c-8db6-bbb1d71cb742",
   "metadata": {},
   "source": [
    "# Module and DASK setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd30181f-20f3-4a95-ab67-43b59276f4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/all/Model/CESM2/Earth_System_Predictability/ASSM/Aleph'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DASK client set\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dask.distributed import Client\n",
    "# client = Client(scheduler_file='/proj/kimyy/Dropbox/source/python/all/mpi/scheduler.json', threads_per_worker=2, n_workers=6)\n",
    "client = Client(scheduler_file='/proj/kimyy/Dropbox/source/python/all/mpi/scheduler.json')\n",
    "# client = Client(scheduler_file='/proj/kimyy/Dropbox/source/python/all/mpi/scheduler_10.json')  \n",
    "\n",
    "def setup_module_path():\n",
    "    module_path = '/proj/kimyy/Dropbox/source/python/all/Modules/CESM2'\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "client.run(setup_module_path)\n",
    "\n",
    "client\n",
    "\n",
    "# get path for path changes in Jupyter notebook: File - Open from Path - insert relative_path\n",
    "notebook_path = os.path.abspath(\".\")\n",
    "_, _, relative_path = notebook_path.partition('/all/')\n",
    "relative_path = '/all/' + relative_path\n",
    "relative_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d374e9-1530-41fc-ac08-850302ae14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load public modules\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.path as mpath\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy import stats\n",
    "from scipy.interpolate import griddata\n",
    "import cmocean\n",
    "from cmcrameri import cm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import pop_tools\n",
    "from pprint import pprint\n",
    "import time\n",
    "import subprocess\n",
    "import re as re_mod\n",
    "import cftime\n",
    "import datetime\n",
    "from scipy.stats import ttest_1samp\n",
    "import xcesm\n",
    "# from scipy.stats import pearsonr\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23400be5-6517-4bb2-9be9-fa0b74cd4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load private modules\n",
    "\n",
    "import sys\n",
    "sys.path.append('/proj/kimyy/Dropbox/source/python/all/Modules/CESM2')\n",
    "from KYY_CESM2_preprocessing import CESM2_config\n",
    "\n",
    "savefilepath = \"/mnt/lustre/proj/kimyy/tmp_python/HCST_skills_HCST-LE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a146a7-52ee-414e-8cb7-c35a0ffb66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change variables by command+F, for S-ST, T-REFHT, T-WS, G-PP, S-SH, P-SL, P-RECT, p-hotoC_TOT_zint_100m, F-AREA_BURNED (not for N-O3). \n",
    "\n",
    "cfg_var_FAREA_BURNED=CESM2_config()\n",
    "cfg_var_FAREA_BURNED.year_s=1960\n",
    "cfg_var_FAREA_BURNED.year_e=2020\n",
    "cfg_var_FAREA_BURNED.setvar('FAREA_BURNED')\n",
    "\n",
    "start_date = cftime.DatetimeNoLeap(cfg_var_FAREA_BURNED.year_s, 2, 1)\n",
    "end_date = cftime.DatetimeNoLeap(cfg_var_FAREA_BURNED.year_e+1, 1, 1)\n",
    "\n",
    "ds_grid = pop_tools.get_grid('POP_gx1v7')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96be5df-9c61-456f-aa74-00d3928c9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_coords_bgc_surface(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        ds = ds.sel(time=slice(sd, ed))\n",
    "        ds = ds.isel(z_t=0) \n",
    "        ds_rgd = ds[varname].utils.regrid()\n",
    "\n",
    "        new_time = ds_rgd.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds_rgd = ds_rgd.assign_coords(time=new_time)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds_rgd\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)\n",
    "\n",
    "\n",
    "def process_coords_2d(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        ds = ds.sel(time=slice(sd, ed))\n",
    "        # ds_rgd = ds[varname].utils.regrid()\n",
    "        # new_time = ds_rgd.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        # ds_rgd = ds_rgd.assign_coords(time=new_time)\n",
    "        new_time = ds.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds = ds.assign_coords(time=new_time)      \n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)\n",
    "\n",
    "\n",
    "\n",
    "def process_coords_bgc_surface_hcst(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        # ds = ds.isel(z_t_150m=slice(0,10)) \n",
    "        ds = ds.isel(z_t_150m=0) \n",
    "        ds_rgd = ds[varname].utils.regrid()\n",
    "\n",
    "        new_time = ds_rgd.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds_rgd = ds_rgd.assign_coords(time=new_time)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds_rgd\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)\n",
    "\n",
    "\n",
    "def process_coords_2d_hcst(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        # ds_rgd = ds[varname].utils.regrid()\n",
    "        # new_time = ds_rgd.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        # ds_rgd = ds_rgd.assign_coords(time=new_time)\n",
    "        new_time = ds.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds = ds.assign_coords(time=new_time)\n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f25d1caa-4568-45bd-87d7-66c8c811cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for reading LE, 0: 18.6246395111084\n",
      "elasped time for reading LE, 1: 22.346392393112183\n",
      "elasped time for reading LE, 2: 26.134681224822998\n",
      "elasped time for reading LE, 3: 30.195822715759277\n",
      "elasped time for reading LE, 4: 33.97082448005676\n",
      "elasped time for reading LE, 5: 37.98354983329773\n",
      "elasped time for reading LE, 6: 41.898600816726685\n",
      "elasped time for reading LE, 7: 45.89781665802002\n",
      "elasped time for reading LE, 8: 49.91686415672302\n",
      "elasped time for reading LE, 9: 53.750648021698\n",
      "elasped time for reading LE, 10: 57.87181043624878\n",
      "elasped time for reading LE, 11: 63.85164761543274\n",
      "elasped time for reading LE, 12: 67.76712846755981\n",
      "elasped time for reading LE, 13: 71.71145749092102\n",
      "elasped time for reading LE, 14: 75.72621846199036\n",
      "elasped time for reading LE, 15: 79.71646285057068\n",
      "elasped time for reading LE, 16: 84.24417114257812\n",
      "elasped time for reading LE, 17: 88.54368925094604\n",
      "elasped time for reading LE, 18: 92.62890291213989\n",
      "elasped time for reading LE, 19: 96.98308396339417\n",
      "elasped time for reading LE, 20: 100.77417254447937\n",
      "elasped time for reading LE, 21: 104.53322553634644\n",
      "elasped time for reading LE, 22: 108.87853217124939\n",
      "elasped time for reading LE, 23: 112.9559166431427\n",
      "elasped time for reading LE, 24: 117.11684894561768\n",
      "elasped time for reading LE, 25: 120.98174786567688\n",
      "elasped time for reading LE, 26: 125.03312134742737\n",
      "elasped time for reading LE, 27: 128.81807327270508\n",
      "elasped time for reading LE, 28: 132.96762108802795\n",
      "elasped time for reading LE, 29: 137.2453052997589\n",
      "elasped time for reading LE, 30: 141.5632722377777\n",
      "elasped time for reading LE, 31: 145.60346174240112\n",
      "elasped time for reading LE, 32: 149.87163972854614\n",
      "elasped time for reading LE, 33: 154.03061318397522\n",
      "elasped time for reading LE, 34: 158.08224201202393\n",
      "elasped time for reading LE, 35: 162.11522221565247\n",
      "elasped time for reading LE, 36: 166.21417665481567\n",
      "elasped time for reading LE, 37: 170.1782989501953\n",
      "elasped time for reading LE, 38: 174.1706302165985\n",
      "elasped time for reading LE, 39: 180.05245971679688\n",
      "elasped time for reading LE, 40: 184.3660387992859\n",
      "elasped time for reading LE, 41: 188.4104359149933\n",
      "elasped time for reading LE, 42: 192.6478750705719\n",
      "elasped time for reading LE, 43: 196.99731492996216\n",
      "elasped time for reading LE, 44: 200.98699951171875\n",
      "elasped time for reading LE, 45: 204.73806977272034\n",
      "elasped time for reading LE, 46: 208.52489161491394\n",
      "elasped time for reading LE, 47: 212.28387093544006\n",
      "elasped time for reading LE, 48: 216.01782131195068\n",
      "elasped time for reading LE, 49: 220.25256276130676\n",
      "elasped time for reading LE, 49: 278.445698261261\n"
     ]
    }
   ],
   "source": [
    "# Read LE dataset (FAREA_BURNED)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cfg_var_FAREA_BURNED.LE_path_load(cfg_var_FAREA_BURNED.var)\n",
    "\n",
    "fpath_FAREA_BURNED = savefilepath + \"/LE_FAREA_BURNED_output*.nc\"\n",
    "\n",
    "tmp_comp=cfg_var_FAREA_BURNED.comp\n",
    "cfg_var_FAREA_BURNED.LE_ds = []\n",
    "for imem in range(0, len(cfg_var_FAREA_BURNED.LE_file_list[0])):\n",
    "    FAREA_BURNED_LE_ds_tmp = xr.open_mfdataset(cfg_var_FAREA_BURNED.LE_file_list[0][imem], \n",
    "                           chunks={'time': 5}, \n",
    "                           combine='nested',\n",
    "                           parallel=True,\n",
    "                           preprocess=lambda ds: process_coords_2d(ds, start_date, end_date, 'FAREA_BURNED', tmp_comp),\n",
    "                           decode_cf=True, \n",
    "                           decode_times=True)\n",
    "    \n",
    "    FAREA_BURNED_LE_ds_tmp = FAREA_BURNED_LE_ds_tmp.expand_dims({'ens_LE': 1})\n",
    "    cfg_var_FAREA_BURNED.LE_ds.append(FAREA_BURNED_LE_ds_tmp)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('elasped time for reading LE, ' + str(imem) + ': ' + str(elapsed_time))\n",
    "\n",
    "cfg_var_FAREA_BURNED.LE_ds = xr.concat(cfg_var_FAREA_BURNED.LE_ds, dim='ens_LE')\n",
    "cfg_var_FAREA_BURNED.LE_ds['ens_LE']=range(0, len(cfg_var_FAREA_BURNED.LE_file_list[0]))\n",
    "cfg_var_FAREA_BURNED.LE_ds=cfg_var_FAREA_BURNED.LE_ds.compute()\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for reading LE, ' + str(imem) + ': ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e81b47d4-73da-4b5d-b4ab-664b308438fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for reading HCST FAREA_BURNED, 0: 20.507572650909424\n",
      "elasped time for reading HCST FAREA_BURNED, 1: 21.33206558227539\n",
      "elasped time for reading HCST FAREA_BURNED, 2: 22.067594528198242\n",
      "elasped time for reading HCST FAREA_BURNED, 3: 22.80449390411377\n",
      "elasped time for reading HCST FAREA_BURNED, 4: 23.541842937469482\n",
      "elasped time for reading HCST FAREA_BURNED, 5: 24.610600471496582\n",
      "elasped time for reading HCST FAREA_BURNED, 6: 25.42611026763916\n",
      "elasped time for reading HCST FAREA_BURNED, 7: 26.18414545059204\n",
      "elasped time for reading HCST FAREA_BURNED, 8: 27.291417598724365\n",
      "elasped time for reading HCST FAREA_BURNED, 9: 28.082486867904663\n",
      "elasped time for reading HCST FAREA_BURNED, 10: 29.141440868377686\n",
      "elasped time for reading HCST FAREA_BURNED, 11: 30.1328547000885\n",
      "elasped time for reading HCST FAREA_BURNED, 12: 30.907535314559937\n",
      "elasped time for reading HCST FAREA_BURNED, 13: 31.704253435134888\n",
      "elasped time for reading HCST FAREA_BURNED, 14: 32.783787965774536\n",
      "elasped time for reading HCST FAREA_BURNED, 15: 33.65352988243103\n",
      "elasped time for reading HCST FAREA_BURNED, 16: 34.44158720970154\n",
      "elasped time for reading HCST FAREA_BURNED, 17: 35.175148010253906\n",
      "elasped time for reading HCST FAREA_BURNED, 18: 35.92365622520447\n",
      "elasped time for reading HCST FAREA_BURNED, 19: 36.722983837127686\n",
      "elasped time for reading HCST FAREA_BURNED, 20: 37.4968798160553\n",
      "elasped time for reading HCST FAREA_BURNED, 21: 38.49779534339905\n",
      "elasped time for reading HCST FAREA_BURNED, 22: 39.307018518447876\n",
      "elasped time for reading HCST FAREA_BURNED, 23: 40.053755044937134\n",
      "elasped time for reading HCST FAREA_BURNED, 24: 40.860045433044434\n",
      "elasped time for reading HCST FAREA_BURNED, 25: 41.649181842803955\n",
      "elasped time for reading HCST FAREA_BURNED, 26: 42.40520763397217\n",
      "elasped time for reading HCST FAREA_BURNED, 27: 43.32460856437683\n",
      "elasped time for reading HCST FAREA_BURNED, 28: 44.09230852127075\n",
      "elasped time for reading HCST FAREA_BURNED, 29: 44.82237267494202\n",
      "elasped time for reading HCST FAREA_BURNED, 30: 45.58801054954529\n",
      "elasped time for reading HCST FAREA_BURNED, 31: 46.371479511260986\n",
      "elasped time for reading HCST FAREA_BURNED, 32: 47.08870220184326\n",
      "elasped time for reading HCST FAREA_BURNED, 33: 48.10939931869507\n",
      "elasped time for reading HCST FAREA_BURNED, 34: 48.836323499679565\n",
      "elasped time for reading HCST FAREA_BURNED, 35: 49.92963767051697\n",
      "elasped time for reading HCST FAREA_BURNED, 36: 50.81466245651245\n",
      "elasped time for reading HCST FAREA_BURNED, 37: 51.601574182510376\n",
      "elasped time for reading HCST FAREA_BURNED, 38: 52.600252866744995\n",
      "elasped time for reading HCST FAREA_BURNED, 39: 53.322861671447754\n",
      "elasped time for reading HCST FAREA_BURNED, 40: 54.08714985847473\n",
      "elasped time for reading HCST FAREA_BURNED, 41: 54.83190560340881\n",
      "elasped time for reading HCST FAREA_BURNED, 42: 55.60830283164978\n",
      "elasped time for reading HCST FAREA_BURNED, 43: 56.44742941856384\n",
      "elasped time for reading HCST FAREA_BURNED, 44: 57.182090520858765\n",
      "elasped time for reading HCST FAREA_BURNED, 45: 57.99058175086975\n",
      "elasped time for reading HCST FAREA_BURNED, 46: 58.70746684074402\n",
      "elasped time for reading HCST FAREA_BURNED, 47: 59.414554834365845\n",
      "elasped time for reading HCST FAREA_BURNED, 48: 60.18122839927673\n",
      "elasped time for reading HCST FAREA_BURNED, 49: 60.96808838844299\n",
      "elasped time for reading HCST FAREA_BURNED, 50: 61.68247938156128\n",
      "elasped time for reading HCST FAREA_BURNED, 51: 62.67486548423767\n",
      "elasped time for reading HCST FAREA_BURNED, 52: 63.32045221328735\n",
      "elasped time for reading HCST FAREA_BURNED, 53: 64.39048433303833\n",
      "elasped time for reading HCST FAREA_BURNED, 54: 65.06483387947083\n",
      "elasped time for reading HCST FAREA_BURNED, 55: 65.76087951660156\n",
      "elasped time for reading HCST FAREA_BURNED, 56: 66.49181485176086\n",
      "elasped time for reading HCST FAREA_BURNED, 57: 67.28510332107544\n",
      "elasped time for reading HCST FAREA_BURNED, 58: 68.02564549446106\n",
      "elasped time for reading HCST FAREA_BURNED, 59: 69.01866674423218\n",
      "elasped time for reading HCST FAREA_BURNED, 60: 70.07583022117615\n",
      "elasped time for reading HCST FAREA_BURNED, 60: 143.11922693252563\n"
     ]
    }
   ],
   "source": [
    "# HCST FAREA_BURNED\n",
    "\n",
    "cfg_var_FAREA_BURNED.HCST_ds = []\n",
    "HCST_ds_xr = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cfg_var_FAREA_BURNED.HCST_path_load(cfg_var_FAREA_BURNED.var)\n",
    "\n",
    "for iyear in range(0, len(cfg_var_FAREA_BURNED.HCST_file_list)):\n",
    "    FAREA_BURNED_HCST_ds_tmp = xr.open_mfdataset(cfg_var_FAREA_BURNED.HCST_file_list[iyear], \n",
    "                           chunks={'time': 4}, \n",
    "                           combine='nested',\n",
    "                           concat_dim=[[*cfg_var_FAREA_BURNED.HCST_ensembles], 'year'], \n",
    "                           parallel=True,\n",
    "                           preprocess=lambda ds: process_coords_2d_hcst(ds, start_date, end_date, 'FAREA_BURNED', tmp_comp),\n",
    "                           decode_cf=True, \n",
    "                           decode_times=True)\n",
    "    \n",
    "    FAREA_BURNED_HCST_ds_tmp = FAREA_BURNED_HCST_ds_tmp.rename({\"year\": \"lyears\"})\n",
    "    FAREA_BURNED_HCST_ds_tmp['lyears']=range(1,6)\n",
    "    FAREA_BURNED_HCST_ds_tmp = FAREA_BURNED_HCST_ds_tmp.expand_dims({'iyear': 1})\n",
    "    \n",
    "    cfg_var_FAREA_BURNED.HCST_ds.append(FAREA_BURNED_HCST_ds_tmp)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('elasped time for reading HCST FAREA_BURNED, ' + str(iyear) + ': ' + str(elapsed_time))\n",
    "\n",
    "cfg_var_FAREA_BURNED.HCST_ds = xr.concat(cfg_var_FAREA_BURNED.HCST_ds, dim='iyear')\n",
    "cfg_var_FAREA_BURNED.HCST_ds = cfg_var_FAREA_BURNED.HCST_ds.rename({\"concat_dim\": \"ens_HCST\"})\n",
    "cfg_var_FAREA_BURNED.HCST_ds['ens_HCST']=range(0, len(cfg_var_FAREA_BURNED.HCST_file_list[0]))\n",
    "cfg_var_FAREA_BURNED.HCST_ds['iyear']=range(cfg_var_FAREA_BURNED.year_s, cfg_var_FAREA_BURNED.year_e+1)\n",
    "cfg_var_FAREA_BURNED.HCST_ds=cfg_var_FAREA_BURNED.HCST_ds.compute()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for reading HCST FAREA_BURNED, ' + str(iyear) + ': ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b3bb7f-bd1f-4f8e-aa77-3de530cb5ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_var_FAREA_BURNED.HCST_ds_yearly = cfg_var_FAREA_BURNED.HCST_ds.sel(iyear=slice(\"1960-01-01\", \"2020-12-31\")).isel(lyears=0).rename({\"iyear\": \"year\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a4cc741-848e-4dfa-9320-839b4dd82878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rolling mean variables (FAREA_BURNED)\n",
    "\n",
    "cfg_var_FAREA_BURNED.LE_ds_4yr = cfg_var_FAREA_BURNED.LE_ds.rolling(year=4, min_periods=4).mean()\n",
    "obs_rolling_time_mean = cfg_var_FAREA_BURNED.LE_ds['year'].rolling(year=4, min_periods=4).mean()\n",
    "cfg_var_FAREA_BURNED.LE_ds_4yr = cfg_var_FAREA_BURNED.LE_ds_4yr.assign_coords(year=obs_rolling_time_mean)\n",
    "valid_index = np.where(~np.isnan(cfg_var_FAREA_BURNED.LE_ds_4yr['year']))[0]\n",
    "cfg_var_FAREA_BURNED.LE_ds_4yr = cfg_var_FAREA_BURNED.LE_ds_4yr.isel(year=valid_index)\n",
    "cfg_var_FAREA_BURNED.LE_ds_4yr = cfg_var_FAREA_BURNED.LE_ds_4yr.isel(year=range(1,58))\n",
    "\n",
    "# hcst_da_ly25=cfg_var_FAREA_BURNED.HCST_ds.sel(iyear=slice(\"1996-01-01\", \"2016-12-31\"), lyears=slice(2, 5))\n",
    "hcst_da_ly25=cfg_var_FAREA_BURNED.HCST_ds.sel(iyear=slice(\"1959\", \"2016\"), lyears=slice(2, 5))\n",
    "cfg_var_FAREA_BURNED.HCST_ds_4yr=hcst_da_ly25.mean(dim='lyears')\n",
    "cfg_var_FAREA_BURNED.HCST_ds_4yr=cfg_var_FAREA_BURNED.HCST_ds_4yr.rename(iyear=\"year\")\n",
    "cfg_var_FAREA_BURNED.HCST_ds_4yr['year']=cfg_var_FAREA_BURNED.LE_ds_4yr['year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c67fb36-8679-4ed5-997f-c4043b64c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for reading HCST FAREA_BURNED, 60: 672.0619738101959\n"
     ]
    }
   ],
   "source": [
    "# get skills\n",
    "start_time = time.time()\n",
    "\n",
    "#LY1\n",
    "corr_FAREA_BURNED_LE_HCST = xr.corr(\n",
    "                            cfg_var_FAREA_BURNED.LE_ds['FAREA_BURNED'].sel(year=slice(\"1964\", \"2020\")), \n",
    "                            cfg_var_FAREA_BURNED.HCST_ds_yearly['FAREA_BURNED'].sel(year=slice(\"1964\", \"2020\")), dim='year')\n",
    "# corr_FAREA_BURNED_LE_HCST_obs_period\n",
    "# obs_years=slice(\"1960\", \"2020\") # others\n",
    "# obs_years=slice(\"1989\", \"2019\") # VODCA2G-PP\n",
    "# obs_years=slice(\"1993\", \"2020\") # SS-H\n",
    "# obs_years=slice(\"1960\", \"2019\") # PREC-T\n",
    "obs_years=slice(\"1998\", \"2020\") # PREC-T\n",
    "\n",
    "corr_FAREA_BURNED_LE_HCST_op = xr.corr(\n",
    "                            cfg_var_FAREA_BURNED.LE_ds['FAREA_BURNED'].sel(year=obs_years), \n",
    "                            cfg_var_FAREA_BURNED.HCST_ds_yearly['FAREA_BURNED'].sel(year=obs_years), dim='year')\n",
    "\n",
    "corr_FAREA_BURNED_LE_HCST_em = xr.corr(\n",
    "                            cfg_var_FAREA_BURNED.LE_ds['FAREA_BURNED'].mean(dim='ens_LE').sel(year=slice(\"1964\", \"2020\")), \n",
    "                            cfg_var_FAREA_BURNED.HCST_ds_yearly['FAREA_BURNED'].mean(dim='ens_HCST').sel(year=slice(\"1964\", \"2020\")), dim='year')\n",
    "# em-obs_period\n",
    "corr_FAREA_BURNED_LE_HCST_op_em = xr.corr(\n",
    "                            cfg_var_FAREA_BURNED.LE_ds['FAREA_BURNED'].mean(dim='ens_LE').sel(year=obs_years), \n",
    "                            cfg_var_FAREA_BURNED.HCST_ds_yearly['FAREA_BURNED'].mean(dim='ens_HCST').sel(year=obs_years), dim='year')\n",
    "\n",
    "\n",
    "#LY2_5\n",
    "corr_FAREA_BURNED_LE_HCST_ly25 = xr.corr(cfg_var_FAREA_BURNED.LE_ds_4yr['FAREA_BURNED'], cfg_var_FAREA_BURNED.HCST_ds_4yr['FAREA_BURNED'], dim='year')\n",
    "# corr_FAREA_BURNED_LE_HCST_obs_period\n",
    "start_int = int(obs_years.start)  \n",
    "stop_int = int(obs_years.stop)    \n",
    "start_int += 2  \n",
    "obs_years_ly25 = slice(str(start_int), str(stop_int))\n",
    "corr_FAREA_BURNED_LE_HCST_ly25_op = xr.corr(cfg_var_FAREA_BURNED.LE_ds_4yr['FAREA_BURNED'].sel(year=obs_years_ly25), cfg_var_FAREA_BURNED.HCST_ds_4yr['FAREA_BURNED'].sel(year=obs_years_ly25), dim='year')\n",
    "\n",
    "corr_FAREA_BURNED_LE_HCST_ly25_em = xr.corr(cfg_var_FAREA_BURNED.LE_ds_4yr['FAREA_BURNED'].mean(dim='ens_LE'), cfg_var_FAREA_BURNED.HCST_ds_4yr['FAREA_BURNED'].mean(dim='ens_HCST'), dim='year')\n",
    "# em-obs_period\n",
    "corr_FAREA_BURNED_LE_HCST_ly25_op_em = xr.corr(cfg_var_FAREA_BURNED.LE_ds_4yr['FAREA_BURNED'].mean(dim='ens_LE').sel(year=obs_years_ly25), cfg_var_FAREA_BURNED.HCST_ds_4yr['FAREA_BURNED'].mean(dim='ens_HCST').sel(year=obs_years_ly25), dim='year')\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for reading HCST FAREA_BURNED, ' + str(iyear) + ': ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92422643-b234-43d4-b117-4f772fbc9c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for saving FAREA_BURNED corr, 60: 3.1589488983154297\n"
     ]
    }
   ],
   "source": [
    " # save temporary file (HCST)\n",
    "start_time = time.time()\n",
    "\n",
    "corr_FAREA_BURNED_LE_HCST.to_netcdf(savefilepath + \"/corr_FAREA_BURNED_LE_HCST\" + \".nc\")\n",
    "corr_FAREA_BURNED_LE_HCST_op.to_netcdf(savefilepath + \"/corr_FAREA_BURNED_LE_HCST_op\" + \".nc\")\n",
    "corr_FAREA_BURNED_LE_HCST_em.to_netcdf(savefilepath + \"/corr_FAREA_BURNED_LE_HCST_em\" + \".nc\")\n",
    "corr_FAREA_BURNED_LE_HCST_op_em.to_netcdf(savefilepath + \"/corr_FAREA_BURNED_LE_HCST_op_em\" + \".nc\")\n",
    "corr_FAREA_BURNED_LE_HCST_ly25.to_netcdf(savefilepath + \"/corr_FAREA_BURNED_LE_HCST_ly25\" + \".nc\")\n",
    "corr_FAREA_BURNED_LE_HCST_ly25_op.to_netcdf(savefilepath + \"/corr_FAREA_BURNED_LE_HCST_ly25_op\" + \".nc\")\n",
    "corr_FAREA_BURNED_LE_HCST_ly25_em.to_netcdf(savefilepath + \"/corr_FAREA_BURNED_LE_HCST_ly25_em\" + \".nc\")\n",
    "corr_FAREA_BURNED_LE_HCST_ly25_op_em.to_netcdf(savefilepath + \"/corr_FAREA_BURNED_LE_HCST_ly25_op_em\" + \".nc\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for saving FAREA_BURNED corr, ' + str(iyear) + ': ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35f04df2-1434-439e-a209-d856d45250f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=19, alpha=0.34, df=17\n",
      "t_crit = 0.982\n",
      "Correlation threshold ≈ ±0.232\n"
     ]
    }
   ],
   "source": [
    "# critical r with alpha=0.1, alpha=0.34\n",
    "N = 19\n",
    "alpha = 0.34  # two-sided, so alpha/2 = 0.05\n",
    "df = N - 2\n",
    "\n",
    "# 1) Find t_crit for a two-sided test at alpha=0.1\n",
    "t_crit = t.ppf(1 - alpha/2, df)  # e.g., ppf(0.95) for the upper 5% tail\n",
    "\n",
    "# 2) Solve for the correlation threshold\n",
    "rho_crit = np.sqrt(t_crit**2 / ((N - 2) + t_crit**2))\n",
    "print(f\"N={N}, alpha={alpha}, df={df}\")\n",
    "print(f\"t_crit = {t_crit:.3f}\")\n",
    "print(f\"Correlation threshold ≈ ±{rho_crit:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
