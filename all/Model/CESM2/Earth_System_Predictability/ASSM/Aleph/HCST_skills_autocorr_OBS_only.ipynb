{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e489583-5013-4f4c-8db6-bbb1d71cb742",
   "metadata": {},
   "source": [
    "# Module and DASK setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd30181f-20f3-4a95-ab67-43b59276f4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/all/Model/CESM2/Earth_System_Predictability/ASSM/Aleph'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DASK client set\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dask.distributed import Client\n",
    "# client = Client(scheduler_file='/proj/kimyy/Dropbox/source/python/all/mpi/scheduler.json', threads_per_worker=2, n_workers=6)\n",
    "client = Client(scheduler_file='/proj/kimyy/Dropbox/source/python/all/mpi/scheduler.json')\n",
    "# client = Client(scheduler_file='/proj/kimyy/Dropbox/source/python/all/mpi/scheduler_10.json')  \n",
    "\n",
    "def setup_module_path():\n",
    "    module_path = '/proj/kimyy/Dropbox/source/python/all/Modules/CESM2'\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "client.run(setup_module_path)\n",
    "\n",
    "client\n",
    "\n",
    "# get path for path changes in Jupyter notebook: File - Open from Path - insert relative_path\n",
    "notebook_path = os.path.abspath(\".\")\n",
    "_, _, relative_path = notebook_path.partition('/all/')\n",
    "relative_path = '/all/' + relative_path\n",
    "relative_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d374e9-1530-41fc-ac08-850302ae14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load public modules\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.path as mpath\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy import stats\n",
    "from scipy.interpolate import griddata\n",
    "import cmocean\n",
    "from cmcrameri import cm\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import pop_tools\n",
    "from pprint import pprint\n",
    "import time\n",
    "import subprocess\n",
    "import re as re_mod\n",
    "import cftime\n",
    "import datetime\n",
    "from scipy.stats import ttest_1samp\n",
    "import xcesm\n",
    "# from scipy.stats import pearsonr\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23400be5-6517-4bb2-9be9-fa0b74cd4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load private modules\n",
    "\n",
    "import sys\n",
    "sys.path.append('/proj/kimyy/Dropbox/source/python/all/Modules/CESM2')\n",
    "from KYY_CESM2_preprocessing import CESM2_config\n",
    "\n",
    "savefilepath = \"/mnt/lustre/proj/kimyy/tmp_python/HCST_skills_autocorr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a146a7-52ee-414e-8cb7-c35a0ffb66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change variables by command+F, for S-ST, T-REFHT, T-WS, P-SL, P-RECT, G-PP, S-SH, p-hotoC_TOT_zint_100m, F-AREA_BURNED (not for N-O3). \n",
    "\n",
    "cfg_var_SST=CESM2_config()\n",
    "cfg_var_SST.year_s=1960\n",
    "cfg_var_SST.year_e=2020\n",
    "cfg_var_SST.setvar('SST')\n",
    "\n",
    "start_date = cftime.DatetimeNoLeap(cfg_var_SST.year_s, 2, 1)\n",
    "end_date = cftime.DatetimeNoLeap(cfg_var_SST.year_e+1, 1, 1)\n",
    "\n",
    "ds_grid = pop_tools.get_grid('POP_gx1v7')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96be5df-9c61-456f-aa74-00d3928c9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_coords_2d(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        ds = ds.sel(time=slice(sd, ed))\n",
    "\n",
    "        new_time = ds.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds = ds.assign_coords(time=new_time)      \n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)\n",
    "\n",
    "\n",
    "def process_coords_2d_obs(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "\n",
    "    if drop:\n",
    "\n",
    "        if 'T' in ds.coords or 'T' in ds.dims:\n",
    "            ds = ds.rename({'T': 'time'})\n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)\n",
    "\n",
    "\n",
    "def process_coords_2d_hcst(\n",
    "    ds, sd, ed, varname, comp, drop=True,\n",
    "    except_coord_vars=[\"time\",\"lon\",\"lat\",\"TLONG\",\"TLAT\"]\n",
    "):\n",
    "    import xcesm\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    except_coord_vars.append(varname)\n",
    "\n",
    "    coord_vars = []\n",
    "    for v in np.array(ds.coords):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "    for v in np.array(ds.data_vars):\n",
    "        if v not in except_coord_vars:\n",
    "            coord_vars.append(v)\n",
    "\n",
    "    if drop:\n",
    "        ds = ds.drop(coord_vars)\n",
    "        # ds_rgd = ds[varname].utils.regrid()\n",
    "        # new_time = ds_rgd.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        # ds_rgd = ds_rgd.assign_coords(time=new_time)\n",
    "        new_time = ds.time - np.array([datetime.timedelta(days=15)] * len(ds.time))\n",
    "        ds = ds.assign_coords(time=new_time)\n",
    "        ds=ds.groupby('time.year').mean(dim='time', skipna=True)\n",
    "        if comp == \"atm\" or comp == \"lnd\":\n",
    "            ds['lat'] = ds['lat'].round(4)\n",
    "            ds['lon'] = ds['lon'].round(4)\n",
    "        if comp == \"ocn\" or comp == \"ice\":\n",
    "            ds['TLAT'] = ds['TLAT'].round(4)\n",
    "            ds['TLONG'] = ds['TLONG'].round(4)\n",
    "        return ds\n",
    "    else:\n",
    "        return ds.set_coords(coord_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a262d497-f157-40a9-b17c-5612e6a9d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for reading OBS: 9.437170028686523\n"
     ]
    }
   ],
   "source": [
    "# Read Observation dataset\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "tmp_comp=cfg_var_SST.comp\n",
    "cfg_var_SST.OBS_path_load(cfg_var_SST.var)\n",
    "\n",
    "cfg_var_SST.OBS_ds = xr.open_mfdataset(cfg_var_SST.OBS_file_list[0][0], \n",
    "                       chunks={'time': 12}, \n",
    "                       parallel=True,\n",
    "                       preprocess=lambda ds: process_coords_2d_obs(ds, start_date, end_date, 'SST', tmp_comp),\n",
    "                       decode_cf=True, \n",
    "                       decode_times=True,)\n",
    "\n",
    "# global mean removal for S-SH\n",
    "if cfg_var_SST.OBS_var=='sla':\n",
    "    print('global mean is removed for sea level')\n",
    "    cfg_var_SST.OBS_ds = cfg_var_SST.OBS_ds.rename({cfg_var_SST.OBS_var: cfg_var_SST.var})\n",
    "    lat_mask = (ds_grid.TLAT >= -60) & (ds_grid.TLAT <= 60)\n",
    "\n",
    "    area_selected = ds_grid.TAREA.where(lat_mask, drop=True)  # 선택된 지역의 면적\n",
    "    SST_selected = cfg_var_SST.OBS_ds[cfg_var_SST.var].where(lat_mask, drop=True)  # 선택된 지역의 SST 데이터\n",
    "\n",
    "    cfg_var_SST.OBS_ds['gm'] = (SST_selected * area_selected).sum(dim=['nlat', 'nlon']) / area_selected.sum(dim=['nlat', 'nlon'])    \n",
    "    cfg_var_SST.OBS_ds['SST'] = cfg_var_SST.OBS_ds[cfg_var_SST.var] - cfg_var_SST.OBS_ds['gm']\n",
    "else:\n",
    "    cfg_var_SST.OBS_ds = cfg_var_SST.OBS_ds.rename({cfg_var_SST.OBS_var: cfg_var_SST.var})\n",
    "\n",
    "# start_year = int(cfg_var_SST.OBS_ds.time.dt.year.values[0])\n",
    "# end_year   = int(cfg_var_SST.OBS_ds.time.dt.year.values[-1])\n",
    "\n",
    "# time_slice = slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\")\n",
    "\n",
    "# if cfg_var_SST.var == 'SST':\n",
    "#     cfg_var_SST.OBS_ds = cfg_var_SST.OBS_ds.assign_coords(\n",
    "#         time=cfg_var_SST.ODA_ds.sel(time=time_slice).time\n",
    "#     )\n",
    "\n",
    "# valid_data_count = (~cfg_var.OBS_ds[cfg_var.var].isnull()).sum(dim='time')\n",
    "# total_time_steps = cfg_var.OBS_ds['time'].size\n",
    "\n",
    "# threshold = 0.8\n",
    "# mask = (valid_data_count / total_time_steps) >= threshold\n",
    "\n",
    "# cfg_var.OBS_ds['mask_80_percent'] = mask\n",
    "# cfg_var.OBS_ds['mask_80_percent'].compute()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for reading OBS: ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764fb2df-b482-4c0e-ae87-1d90ac798e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rolling mean variables, observational period\n",
    "\n",
    "cfg_var_SST.OBS_ds_4yr = cfg_var_SST.OBS_ds.rolling(year=4, min_periods=4).mean()\n",
    "obs_rolling_time_mean = cfg_var_SST.OBS_ds['year'].rolling(year=4, min_periods=4).mean()\n",
    "cfg_var_SST.OBS_ds_4yr = cfg_var_SST.OBS_ds_4yr.assign_coords(year=obs_rolling_time_mean)\n",
    "valid_index = np.where(~np.isnan(cfg_var_SST.OBS_ds_4yr['year']))[0]\n",
    "cfg_var_SST.OBS_ds_4yr = cfg_var_SST.OBS_ds_4yr.isel(year=valid_index)\n",
    "if cfg_var_SST.OBS_ds_4yr.isel(year=0).year == 1961.5:\n",
    "    if cfg_var_SST.OBS_ds_4yr.isel(year=-1).year == 2017.5:\n",
    "        cfg_var_SST.OBS_ds_4yr = cfg_var_SST.OBS_ds_4yr.isel(year=range(1, 57))\n",
    "    else:\n",
    "        cfg_var_SST.OBS_ds_4yr = cfg_var_SST.OBS_ds_4yr.isel(year=range(1, 58))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6f129f-d878-4f69-85af-a240b277a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# individual (OBS)\n",
    "da = cfg_var_SST.OBS_ds['SST'].sel(year=slice(1965, 2020))\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_SST.OBS_var == 'SST' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "autocorr_SST_OBS = xr.corr(da, da_lag1, dim='year')   # ens_OBS, lat, lon\n",
    "\n",
    "\n",
    "# individual 4yr (OBS)\n",
    "da = cfg_var_SST.OBS_ds_4yr['SST'].sel(year=slice(1965, 2020))\n",
    "\n",
    "da = da.where(~np.isclose(da, 0), np.nan) if cfg_var_SST.OBS_var == 'SST' else da\n",
    "da_lag1 = da.shift(year=-1)\n",
    "valid = (~np.isnan(da)) & (~np.isnan(da_lag1))\n",
    "da      = da.where(valid)\n",
    "da_lag1 = da_lag1.where(valid)\n",
    "\n",
    "autocorr_SST_OBS_ds_4yr = xr.corr(da, da_lag1, dim='year')   # ens_OBS, lat, lon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92422643-b234-43d4-b117-4f772fbc9c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasped time for saving SST corr, : 1.6517376899719238\n"
     ]
    }
   ],
   "source": [
    "# save temporary file (HCST)\n",
    "start_time = time.time()\n",
    "\n",
    "autocorr_SST_OBS.to_netcdf(savefilepath + \"/autocorr_SST_OBS\" + \".nc\")\n",
    "autocorr_SST_OBS_ds_4yr.to_netcdf(savefilepath + \"/autocorr_SST_OBS_ds_4yr\" + \".nc\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('elasped time for saving SST corr, '  + ': ' + str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28f67c3e-b6ce-44da-b21c-048409cc8c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/lustre/proj/kimyy/tmp_python/HCST_skills_autocorr'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savefilepath"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
